{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84da0448",
   "metadata": {},
   "source": [
    "# Assignment 2 - Build and Deploy Weather Model\n",
    "\n",
    "## Part 1 (30 points)\n",
    "\n",
    "- successfully run this notebook on your Raspberry Pi\n",
    "- answer questions given in the notebook\n",
    "\n",
    "## Part 2 (10 points)\n",
    "- make a copy of this notebook and call it `Assignment2-Part2`\n",
    "- open the new notebook\n",
    "- using June-2022 data, the BALANCED model has these accuracy for training and test data\n",
    "```\n",
    "    Average model accuracy(training data): 0.7559129612109745\n",
    "    Average model accuracy(test data): 0.7471698113207547\n",
    "```    \n",
    "- use additional features in the \"Build Model - use BALANCED data\" section to improve the model's accuracy\n",
    "- you will not be required to use this model with live BMP280 data\n",
    "- what is your best accuracy from the revised model?\n",
    "- what other changes can you make to improve the model's accuracy?  For example, include more features, improve how Rain/NoRain labels are made, etc.\n",
    "- the higher your model accuracy, the higher your grade\n",
    "   \n",
    "\n",
    "## Part 3 (10 points)\n",
    "\n",
    "- make a copy of this notebook and call it `Assignment2-Part3`\n",
    "- open the new notebook\n",
    "- instead of using training data from June-2022, make needed changes to use training data from July-2022\n",
    "- run the new notebook and make necessary changes to the code (hint: you'll also need to change prg550_assignment2_students.py)\n",
    "- what caused your code to break?  why is this a challenge for data science?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase Jupyter cell width\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625bba7",
   "metadata": {},
   "source": [
    "### set auto reload for user modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import seaborn as sns # import plotting library\n",
    "sns.set_palette('tab10') # see here for reference https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaabef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from prg550_assignment2_student.py for use in this notebook\n",
    "from prg550_assignment2_students import bmp_initialize, bmp_read_values, data_collection, data_clean_prep, model_load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dace5e0",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "############## Set stationID and climateID for weather station ##############\n",
    "stationID, climateID = \"51459\", \"6158731\" # Toronto Pearson\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "########### Set Year, Month, Day to capture 1 month of hourly data ###########\n",
    "year = 2022\n",
    "month = 6\n",
    "day = 1\n",
    "##############################################################################\n",
    "\n",
    "download_date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "\n",
    "print(f\"One month of data will be downloaded for {download_date_str}\\nStationID={stationID} and ClimateID={climateID}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_df = data_collection(stationID, climateID, year, month, day)\n",
    "data_raw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfde3e",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ddb1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_df = data_clean_prep(data_raw_df)\n",
    "data_clean_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077de888",
   "metadata": {},
   "source": [
    "## Additional feature processing - Convert Rain/NoRain to 1/0 for use by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d256e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "\n",
    "fields = ['Temp','StnPress','PRG550_2labels']\n",
    "target_field = 'PRG550_2labels'\n",
    "feature_fields = ['Temp','StnPress' ]\n",
    "\n",
    "df = data_clean_df[fields].copy()\n",
    "\n",
    "# convert Rain/NoRain to binary 1, 0\n",
    "lb = preprocessing.LabelBinarizer() \n",
    "binarized_target = lb.fit_transform(data_clean_df[target_field])\n",
    "s = pd.Series(binarized_target.ravel(), name='PRG550_target') # create pandas series from array named 'target'\n",
    "\n",
    "data_clean_df = data_clean_df.assign(PRG550_target=s) # add binarized labels to data_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85607eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_label = lb.inverse_transform(s) # transform 0's, 1's back to labels\n",
    "target_to_label[:20] # show first 20 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394de076",
   "metadata": {},
   "source": [
    "### Verify new mappings: NoRain-->0 and Rain -->1\n",
    "\n",
    "`NoRain` should map to 0\n",
    "\n",
    "`Rain` should map to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Temp','StnPress','PRG550_2labels']\n",
    "target_field = 'PRG550_target' # <<<<<<<<<<<<<< PRG550_target is the new 1/0 target column\n",
    "feature_fields = ['Temp','StnPress' ]\n",
    "\n",
    "data_clean_df.iloc[8:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b3ddf",
   "metadata": {},
   "source": [
    "### Show data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccb3cf",
   "metadata": {},
   "source": [
    "## Show Cleaned Data with Environment Canada Weather Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = data_clean_df\n",
    "weather_fix_order = ['Mostly Cloudy', 'Cloudy', 'Fog', 'Mainly Clear', 'Clear', 'Drizzle', 'Rain', 'Rain', 'Rain Showers', 'Rain Showers,Fog', 'Rain,Fog', 'Moderate Rain,Fog', 'Moderate Rain Showers', 'Thunderstorms', 'Thunderstorms,Moderate Rain Showers', 'Thunderstorms,Heavy Rain Showers']\n",
    "\n",
    "g = sns.scatterplot(x='Temp', y='StnPress', hue='Weather_fix', hue_order=weather_fix_order, palette = \"coolwarm_r\", data=plot_df)\n",
    "# Put the legend out of the figure\n",
    "g.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb05a0",
   "metadata": {},
   "source": [
    "## Show Cleaned Data with PRG550 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = data_clean_df\n",
    "sns.scatterplot(x='Temp', y='StnPress', hue='PRG550_target', data=plot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaaa6ec",
   "metadata": {},
   "source": [
    "## Check if data is imbalanced between Rain and NoRain classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_clean_df.groupby(target_field)[target_field].count())\n",
    "_temp = data_clean_df.groupby(target_field)[target_field].count().values\n",
    "\n",
    "num_majority = _temp[0]\n",
    "num_minority = _temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b848a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_guess_accuracy = num_majority / (num_majority+num_minority)\n",
    "naive_guess_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f4ddc",
   "metadata": {},
   "source": [
    "## Large class imbalance! \n",
    "We have 10x data imbalance between NoRain and Rain\n",
    "\n",
    "Guessing `NoRain` all the time will give you 91.8% accuracy without even using a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6f8aa",
   "metadata": {},
   "source": [
    "## Correct for class imbalance by creating duplicates of the smaller class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_minority_df = data_clean_df.loc[data_clean_df['PRG550_2labels'] == 'Rain'] # filter only rows having 'Rain'\n",
    "data_clean_majority_df = data_clean_df.loc[data_clean_df['PRG550_2labels'] == 'NoRain'] # filter only rows having 'NoRain'\n",
    "\n",
    "# confirm size of minority and majority data rows same as above\n",
    "(data_clean_minority_df.shape, data_clean_majority_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7725ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Upsample minority class\n",
    "data_clean_minority_upsampled_df = resample(data_clean_minority_df, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=num_majority,    # to match number of samples in majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "data_clean_balanced_df = pd.concat([data_clean_majority_df, data_clean_minority_upsampled_df], axis=0)\n",
    "data_clean_balanced_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3052c",
   "metadata": {},
   "source": [
    "### Confirm classes are now balanced for `data_clean_balanced_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows equal number of 0's (NoRain) and 1's (Rain)\n",
    "data_clean_balanced_df.groupby(target_field)[target_field].count() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0a722",
   "metadata": {},
   "source": [
    "## Build Model - using imbalanced data\n",
    "\n",
    "This section shows what happens when imbalanced data is used to train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5dcd8",
   "metadata": {},
   "source": [
    "### Create feature and target datasets - imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and target dataframes\n",
    "_features = ['Temp', 'StnPress'] # temperature (Temp) and air pressure (StnPress) at weather station are features\n",
    "_target = 'PRG550_target' # Rain/NoRain converted to 1/0\n",
    "\n",
    "df_features = data_clean_df[_features]  # <<<<<<< using dataframe before Rain/NoRain was balanced \n",
    "df_target = data_clean_df[_target]      # <<<<<<< using dataframe before Rain/NoRain was balanced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee86c3",
   "metadata": {},
   "source": [
    "### Split into train and test data subsets - imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "percentage_for_testing = 0.2 # 20% data for testing, 80% for training\n",
    "\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_features\n",
    "    , df_target\n",
    "    , test_size=percentage_for_testing\n",
    "    , random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a94de5",
   "metadata": {},
   "source": [
    "### Show train and test data - imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,4)) # create a figure with two subplots (1 row, 2 columns)\n",
    "\n",
    "# combine df_features_train, df_target_train into one dataframe\n",
    "_plot_train_df = pd.concat([df_features_train, df_target_train], ignore_index=True, sort=False, axis=1) # axis=1 means put columns side-by-side\n",
    "_plot_train_df.columns = ['Temp', 'StnPress', 'PRG550_target'] # rename columns so proper labels appear in graph\n",
    "\n",
    "# combine df_features_test, df_target_test into one dataframe\n",
    "_plot_test_df = pd.concat([df_features_test, df_target_test], ignore_index=True, sort=False, axis=1) # axis=1 means put columns side-by-side\n",
    "_plot_test_df.columns = ['Temp', 'StnPress', 'PRG550_target'] # rename columns so proper labels appear in graph\n",
    "\n",
    "g1 = sns.scatterplot(x='Temp', y='StnPress', hue='PRG550_target', data=_plot_train_df, ax=ax[0])\n",
    "g1.set(title='Env Canada - training subset (imbalanced data)')\n",
    "g2 = sns.scatterplot(x='Temp', y='StnPress', hue='PRG550_target', data=_plot_test_df, ax=ax[1])\n",
    "g2.set(title='Env Canada  - test subset (imbalanced data)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643f3ac",
   "metadata": {},
   "source": [
    "### Instantiate and train logistic regression classifier model - imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "imbalanced_clf = LogisticRegression(random_state=0)\n",
    "imbalanced_clf.fit(X=df_features_train.values, # .values to get numpy representation of array\n",
    "                   y=df_target_train.values # .values to get numpy representation of array\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7df60",
   "metadata": {},
   "source": [
    "### Model Accuracy - imbalanced data\n",
    "\n",
    "Model is not much better than naive guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f895fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_with_train_data = imbalanced_clf.score(df_features_train.values, df_target_train.values)\n",
    "score_wtih_test_data = imbalanced_clf.score(df_features_test.values, df_target_test.values)\n",
    "print(\"Average model accuracy(training data): {0}\\nAverage model accuracy(test data): {1}\\nAccuracy for always guessing 'NoRain': {2}\".format(\n",
    "    score_with_train_data,score_wtih_test_data, naive_guess_accuracy )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288800f",
   "metadata": {},
   "source": [
    "### Save trained model to file - imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "imbalanced_model_filename = 'imbalanced_data_environment_canada_logistic_regression_classifier.joblib'\n",
    "dump(imbalanced_clf, imbalanced_model_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b6fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a5b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33501e9c",
   "metadata": {},
   "source": [
    "## Build Model - use BALANCED data\n",
    "\n",
    "This section shows what happens when imbalanced data is used to train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5470f3",
   "metadata": {},
   "source": [
    "### Create feature and target datasets - imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and target dataframes\n",
    "_features = ['Temp', 'StnPress'] # temperature (Temp) and air pressure (StnPress) at weather station are features\n",
    "_target = 'PRG550_target' # Rain/NoRain converted to 1/0\n",
    "\n",
    "df_features = data_clean_balanced_df[_features]  # <<<<<<< using dataframe AFTER Rain/NoRain was balanced \n",
    "df_target = data_clean_balanced_df[_target]      # <<<<<<< using dataframe AFTER Rain/NoRain was balanced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e70b9c",
   "metadata": {},
   "source": [
    "### Split into train and test data subsets - use BALANCED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0914367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "percentage_for_testing = 0.2 # 20% data for testing, 80% for training\n",
    "\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_features\n",
    "    , df_target\n",
    "    , test_size=percentage_for_testing\n",
    "    , random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06a5e8",
   "metadata": {},
   "source": [
    "### Show train and test data - use BALANCED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14,4)) # create a figure with two subplots (1 row, 2 columns)\n",
    "\n",
    "# combine df_features_train, df_target_train into one dataframe\n",
    "_plot_train_df = pd.concat([df_features_train, df_target_train], ignore_index=True, sort=False, axis=1) # axis=1 means put columns side-by-side\n",
    "_plot_train_df.columns = ['Temp', 'StnPress', 'PRG550_2labels'] # rename columns so proper labels appear in graph\n",
    "\n",
    "# combine df_features_test, df_target_test into one dataframe\n",
    "_plot_test_df = pd.concat([df_features_test, df_target_test], ignore_index=True, sort=False, axis=1) # axis=1 means put columns side-by-side\n",
    "_plot_test_df.columns = ['Temp', 'StnPress', 'PRG550_2labels'] # rename columns so proper labels appear in graph\n",
    "\n",
    "g1 = sns.scatterplot(x='Temp', y='StnPress', hue='PRG550_2labels', data=_plot_train_df, ax=ax[0])\n",
    "g1.set(title='Env Canada - training subset (balanced data)')\n",
    "g2 = sns.scatterplot(x='Temp', y='StnPress', hue='PRG550_2labels', data=_plot_test_df, ax=ax[1])\n",
    "g2.set(title='Env Canada  - test subset (balanced data)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05a0e3",
   "metadata": {},
   "source": [
    "### Instantiate and train logistic regression classifier model - use BALANCED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "balanced_clf = LogisticRegression(random_state=0)\n",
    "balanced_clf.fit(X=df_features_train.values, # .values to get numpy representation of array\n",
    "                   y=df_target_train.values # .values to get numpy representation of array\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5274aba",
   "metadata": {},
   "source": [
    "### Model Accuracy - use BALANCED data\n",
    "\n",
    "Model is not much better than naive guessing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_with_train_data = balanced_clf.score(df_features_train.values, df_target_train.values)\n",
    "score_wtih_test_data = balanced_clf.score(df_features_test.values, df_target_test.values)\n",
    "print(\"Average model accuracy(training data): {0}\\nAverage model accuracy(test data): {1}\".format(\n",
    "    score_with_train_data,score_wtih_test_data, naive_guess_accuracy )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206859e",
   "metadata": {},
   "source": [
    "### Save trained model to file - use BALANCED data\n",
    "\n",
    "save into file: `balanced_data_environment_canada_logistic_regression_classifier.joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9373bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "balanced_model_filename = 'balanced_data_environment_canada_logistic_regression_classifier.joblib'\n",
    "dump(balanced_clf, balanced_model_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b43e13",
   "metadata": {},
   "source": [
    "# Show Decision Boundary of Balanced Model\n",
    "\n",
    "Questions: \n",
    "\n",
    "1. what does the purple area represent?\n",
    "1. what does the yellow area represent?\n",
    "1. what will prediction will your model give if Temperature=20.0 and Pressure=100.5?\n",
    "1. what will prediction will your model give if Temperature=32.0 and Pressure=97.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "_features = ['Temp', 'StnPress'] # temperature (Temp) and air pressure (StnPress) at weather station are features\n",
    "_target = 'PRG550_2labels' # Rain or NoRain\n",
    "\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=balanced_clf, \n",
    "    X=df_features_train[_features].values, \n",
    "    response_method=\"predict\",\n",
    "    alpha=0.4 # use 40% transparency\n",
    ")\n",
    "# DecisionBoundaryDisplay based on matplotlib, using matplotlib's version of scatter()\n",
    "disp.ax_.scatter(x=df_features_train['Temp'], # x-axis for scatter plot\n",
    "                 y=df_features_train['StnPress'], # y-axis for scatter plot\n",
    "                 c=df_target_train,  # use target label to colour data points\n",
    "                 edgecolor=\"k\")\n",
    "plt.title('Balanced Classifier Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ed760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. what does the purple area represent?\n",
    "\n",
    "# type your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161337a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. what does the yellow area represent?\n",
    "\n",
    "# type your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. what will prediction will your model give if Temperature=20.0 and Pressure=100.5?\n",
    "\n",
    "# type your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. what will prediction will your model give if Temperature=32.0 and Pressure=97.5?\n",
    "\n",
    "# type your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67341936",
   "metadata": {},
   "source": [
    "# Plot experimental results\n",
    "\n",
    "Load data from  `experiment_data_YYYYMMDD_HHMMSS.csv` and \n",
    "\n",
    "1. plot Measured_Temperature vs time \n",
    "1. plot Measured_Pressure vs time\n",
    "1. model's prediction vs time (ie Prediction_Label)\n",
    "\n",
    "Your the x- and y-axis of your plots should be similar these three charts\n",
    "<div>\n",
    "<img src=\"plot_experimental_results.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lines of code to load your captured data into dataframe: realtime_data_df\n",
    "\n",
    "# pseudo code:\n",
    "# read csv file into realtime_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c524ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. your code here to plot Measured_Temperature vs time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df882d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. your code here to plot Measured_Pressure vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. your code here to plot your model's prediction vs time (ie Prediction_Label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
