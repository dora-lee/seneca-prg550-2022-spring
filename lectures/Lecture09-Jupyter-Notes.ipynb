{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78275ea8",
   "metadata": {},
   "source": [
    "# Lecture 9\n",
    "\n",
    "This lecture will provide you with an overview of the [scikit-learn](https://scikit-learn.org/stable/index.html) machine learning library in Python.  You will gain an understanding and experience working with a classification model using two input features along with their labels.\n",
    "\n",
    "An artificial dataset will be used to give you experience changing the input data and seeing how it will impact the effectiveness of the classifcation model\n",
    "\n",
    "This lecture notebook walks you through:\n",
    "1. Creating two synthetic datasets each having two clusters, similar to final Rain/NoRain dataset for Assignment 2\n",
    "1. Using plots to visualize the synthetic datasets\n",
    "    1. change `class_sep` and `random_state` to generate different versions of synthetic data\n",
    "1. Building a model by \n",
    "    1. selecting columns from cleaned data to be features and a column to be the target label.  \n",
    "    1. splitting the features and target label into train and test datasets\n",
    "\n",
    "For the synthetic dataset:\n",
    "1. Use `temperature` and `pressure` as features. Use `weather_label` as target label\n",
    "1. Separate data into training and test datasets\n",
    "1. Build a LogisticRegression classification model to predict `weather_label` based on input features `temperature` and `pressure`\n",
    "1. Calculate model accuracy on the training and test datasets\n",
    "\n",
    "Data visualization is an important tool to show what is happening as you perform operations on data.  You will use plotting functions from the `seaborn` [graphing library](https://seaborn.pydata.org/tutorial.html) to show:\n",
    "1. What the two synthetic datasets look like\n",
    "1. What data was selected to be in the training and test subsets\n",
    "1. What decision boundary the model uses to decide if a datapoint belongs in class 0 or class 1\n",
    "1. What decision boundary the model uses to decide if a datapoint belongs in class 0 or class 1\n",
    "1. Where the model made a prediction mistake in the test dataset\n",
    "1. Show the result asking a model to make predictions on new data that is very different from data that it was trained on\n",
    "\n",
    "### Helpful links\n",
    "\n",
    "[Scikit-Learn Tutorial](https://scikit-learn.org/stable/tutorial/basic/tutorial.html#machine-learning-the-problem-setting)\n",
    "\n",
    "[Scikit-Learn Glossary of Common Terms and API Elements](https://scikit-learn.org/stable/glossary.html)\n",
    "\n",
    "[Seaborn graphing library](https://seaborn.pydata.org/tutorial.html)\n",
    "\n",
    "[Seaborn example gallery](https://seaborn.pydata.org/examples/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a228b45",
   "metadata": {},
   "source": [
    "# Jupyter Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e149f",
   "metadata": {},
   "source": [
    "### Change Jupyter gui for wider cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb9115e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase Jupyter cell width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9cece",
   "metadata": {},
   "source": [
    "# Import libraries needed for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71499cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set pandas options \n",
    "pd.set_option('display.max_columns', None) # show all columns\n",
    "pd.set_option('display.max_rows', None) # show all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ebcb29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification # import function to generate synthetic (ie fake) test data\n",
    "from sklearn.model_selection import train_test_split # import function to split cleaned data into train and test subsets\n",
    "from sklearn.linear_model import LogisticRegression # import LogisticRegression model for classification\n",
    "from sklearn.inspection import DecisionBoundaryDisplay # import DecisionBoundaryDisplay to see model decision boundary\n",
    "\n",
    "import matplotlib.pyplot as plt # import matplotib.pyplot for plotting\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns # import plotting library\n",
    "sns.set_palette('tab10') # set to bright 10-colour palatte see here for reference https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecd51e",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data\n",
    "\n",
    "Use `make_classification` to create two clusters from two input features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df81a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification # import function to generate synthetic (ie fake) test data\n",
    "\n",
    "# create first dataset that has clear separation between the two classes using class_sep=1.5\n",
    "# X1, y1 are numpy arrays --> X1 are the features, y1 is the label \n",
    "X1,y1 = make_classification(n_samples=1000,                   # 1000 sample rows\n",
    "                            n_features=2, n_classes=2,        # each row has two input features and belong to one of two classes\n",
    "                            class_sep=1.5,                    # how far the classes are from each other <<< go ahead and change this value to see how this changes model accuracy below\n",
    "                            n_clusters_per_class=1, n_redundant=0, n_repeated=0, n_informative=2, flip_y=0, # keep these values as-is\n",
    "                            weights=[0.5,0.5],                # set to 50%/50% for same number of samples row in each class\n",
    "                            random_state=93#95, 99                   # set for repeatability <<< go ahead and change this to see different data being created\n",
    "                           )\n",
    "\n",
    "# create second dataset that has overlap between the two classes --> class_sep=0.5\n",
    "# X2, y2 are numpy arrays --> X2 are the features, y2 is the label \n",
    "X2,y2 = make_classification(n_samples=1000,                   # 1000 sample rows\n",
    "                            n_features=2, n_classes=2,        # each row has two input features and belong to one of two classes\n",
    "                            class_sep=0.25,                    # how far the classes are from each other <<< go ahead and change this value to see how this changes model accuracy below\n",
    "                            n_clusters_per_class=1, n_redundant=0, n_repeated=0, n_informative=2, flip_y=0, # keep these values as-is\n",
    "                            weights=[0.5,0.5],                # set to 50%/50% for two classes that are balanced\n",
    "                            random_state=43                   # set for repeatability <<< go ahead and change this to see different data being created\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bca8de",
   "metadata": {},
   "source": [
    "### Create dataframe for dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a552c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['temperature', 'pressure', 'weather_label']\n",
      "Average Temp, Press: [1.536482639515635, 0.009694903615141613]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>weather_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368800</td>\n",
       "      <td>-3.017312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.332815</td>\n",
       "      <td>1.187653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.793640</td>\n",
       "      <td>-1.652942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  pressure  weather_label\n",
       "0     0.368800 -3.017312              1\n",
       "1     3.332815  1.187653              0\n",
       "2     1.793640 -1.652942              1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data1_df = pd.DataFrame({'temperature': X1[:,0], 'pressure': X1[:,1], 'weather_label':y1})\n",
    "print(\"Column names:\", clean_data1_df.columns.tolist())\n",
    "\n",
    "print(\"Average Temp, Press:\", clean_data1_df[['temperature', 'pressure']].mean().tolist())\n",
    "\n",
    "clean_data1_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88492261",
   "metadata": {},
   "source": [
    "### Create dataframe for dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd6c7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['temperature', 'pressure', 'weather_label']\n",
      "Average Temp, Press: [0.04112007358369708, 0.030806103519856295]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>weather_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.886261</td>\n",
       "      <td>0.837042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.300718</td>\n",
       "      <td>-0.269308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602021</td>\n",
       "      <td>0.166823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  pressure  weather_label\n",
       "0     0.886261  0.837042              1\n",
       "1    -0.300718 -0.269308              0\n",
       "2     0.602021  0.166823              0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data2_df = pd.DataFrame({'temperature': X2[:,0], 'pressure': X2[:,1], 'weather_label':y2})\n",
    "print(\"Column names:\", clean_data2_df.columns.tolist())\n",
    "\n",
    "print(\"Average Temp, Press:\", clean_data2_df[['temperature', 'pressure']].mean().tolist())\n",
    "\n",
    "clean_data2_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed509fc1",
   "metadata": {},
   "source": [
    "### Show the two datasets side-by-side\n",
    "\n",
    "1. Notice how the two classes are somewhat separated for Dataset 1.  This is because `class_sep` was set to 1.5\n",
    "1. For Dataset 2, the two classes show quite a bit of overlap.  This is because `class_sep` was set a smaller value of 0.25 (basically less separation)\n",
    "\n",
    "With Dataset 1, it's not too hard to use a straight line to separate the two classes.  Because of how the classes overlap for Dataset 2, it will be more challenging to determine where to draw the separation line.  \n",
    "\n",
    "Go ahead and try changing `class_sep` above and re-run the above cells and the one below and see the effect yourself\n",
    "\n",
    "The machine learing model will find a boundary that will give the highest accuracy on the training data\n",
    "\n",
    "In practical applications, you're more likely to encounter situations similar to Dataset 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eed74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Dataset 2')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x677cb610> (for post_execute):\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\n",
    "g1 = sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=clean_data1_df, ax=ax[0])\n",
    "g1.set(title='Dataset 1') \n",
    "g2 = sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=clean_data2_df, ax=ax[1])\n",
    "g2.set(title='Dataset 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866376f",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "From the synthetic data, features and target columns are selected to train the weather prediction model.\n",
    "\n",
    "- create a dataframe `df_features` containing these fields `['temperature','pressure']`\n",
    "- create a dataframe `df_target` containing labels used for classification `['weather_label']`\n",
    "- split the features and target data into training and test sets using `sklearn.model_selection.train_test_split()`\n",
    "- instantiate a `sklearn.linear_model.LogisticRegression()` model and train it using `df_features`, `df_target`\n",
    "- check model accuracy using `.score()` function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96e26e",
   "metadata": {},
   "source": [
    "### Create feature and target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce27cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and target dataframes\n",
    "_features = ['temperature', 'pressure']\n",
    "_target = 'weather_label'\n",
    "\n",
    "df_features = clean_data1_df[_features]\n",
    "df_target = clean_data1_df[_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec08552",
   "metadata": {},
   "source": [
    "### Split into train and test data subsets\n",
    "\n",
    "The source data used to build a machine learning model is typically split into 2 subsets: training and test.\n",
    "\n",
    "1. training data\n",
    "    1. training data is used to train the model\n",
    "1. test data\n",
    "    1. test data is used to evaluate how well the model performs on new data.\n",
    "    \n",
    "Good accuracy on the test data means the model generalized well.  ie it is able to make good predictions on data it has never seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # import function to split cleaned data into train and test subsets\n",
    "\n",
    "# split data into 80% train and 20% test datasets\n",
    "percentage_for_testing = 0.2 # <<<<<<<<< set to 0.2 for 20% data for testing, 80% for training\n",
    "\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = train_test_split(\n",
    "    df_features\n",
    "    , df_target\n",
    "    , test_size=percentage_for_testing  # set percentage of data reserved for testing\n",
    "    , random_state=42 # set to any number you want for repeatability\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918fd1c3",
   "metadata": {},
   "source": [
    "### Visualize train and test datasets\n",
    "\n",
    "Note 20% of the data are on the right chart and 80% are in the left.  \n",
    "\n",
    "This is controlled by `percentage_for_testing` in the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad54be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df_features_train, df_target_train into one dataframe for seaborn to plot\n",
    "_plot_train_df = pd.concat([df_features_train, df_target_train], ignore_index=True, sort=False, axis=1) # axis=1 means put columns side-by-side\n",
    "_plot_train_df.columns =  ['temperature', 'pressure', 'weather_label'] # rename columns so proper labels appear in graph\n",
    "\n",
    "# combine df_features_test, df_target_test into one dataframe for seaborn to plot\n",
    "_plot_test_df = pd.concat([df_features_test, df_target_test], ignore_index=True, sort=False, axis=1) # axis=1 means put columns side-by-side\n",
    "_plot_test_df.columns =  ['temperature', 'pressure', 'weather_label'] # rename columns so proper labels appear in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b191139",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_train_df.head(3) # show the data frame used for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_test_df.head(3)  # show the data frame used for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111230b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8,4)) # create a figure with two subplots (1 row, 2 columns)\n",
    "\n",
    "sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=_plot_train_df, ax=ax[0]).set(title='Training data subset')\n",
    "sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=_plot_test_df, ax=ax[1]).set(title='Test data subset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbfb27c",
   "metadata": {},
   "source": [
    "### Instantiate and train logistic regression classifier model\n",
    "\n",
    "A `LogisticRegression` classifier is instantiated and assigned to variable `clf`\n",
    "\n",
    "In order to train the classifier, the `fit()` method is called and with feature (`X=`) and target (`y=`) variables as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdcd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # import LogisticRegression model\n",
    "\n",
    "# instantiate and train logistic regression classifier model\n",
    "clf = LogisticRegression(random_state=0)  # again, setting random_state to known value for repeatbility\n",
    "\n",
    "clf.fit(X=df_features_train.values, y=df_target_train.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5510d40",
   "metadata": {},
   "source": [
    "### Calculate mean model accuracy on training and test data\n",
    "\n",
    "To evaluate how well the model performs, it's accuracy is measured using training data as well as test data\n",
    "\n",
    "Prediction accuracy is typically higher for training data than for test data, Why?\n",
    "- During the `fit()` process, the model optimized for best accuracy using training data.\n",
    "- As test data has not been seen by the model, imperfect model generalization produces worse accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a421f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_with_train_data = clf.score(df_features_train, df_target_train)\n",
    "score_wtih_test_data = clf.score(df_features_test, df_target_test)\n",
    "print(\"Average model accuracy(training data): {0}\\nAverage model accuracy(test data): {1}\".format(\n",
    "    score_with_train_data,score_wtih_test_data )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5eb90d",
   "metadata": {},
   "source": [
    "## Show decision Boundary of model\n",
    "\n",
    "This section will show you how to visualize the decision bounday the LogisticRegression classifer found when using the two features (`temperature`, `pressure`) to predict `weather_label`\n",
    "\n",
    "`DecisionBoundaryDisplay` will show the boundary it uses to separate the two classes.  \n",
    "- For points one side of boundary, it will assign to one class (yellow)\n",
    "- For points on other side of boundary, it will assign to the second class (purple)\n",
    "\n",
    "The chart below also overlays the data points along with the actual class in bright yellow and dark purple.\n",
    "\n",
    "For bright yellow points lying in the purple region, the model will give an incorrect prediction.\n",
    "\n",
    "For dark purple points lying in the yellow region, the model will also give an incorrect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a684aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data1_df.head(2) # show data frame as reminder of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669571ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # import matplotib.pyplot for plotting\n",
    "from sklearn.inspection import DecisionBoundaryDisplay # import DecisionBoundaryDisplay to see model decision boundary\n",
    "\n",
    "# this will produce the 2-coloured background \n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=clf,                          # clf is the classifier trained above\n",
    "    X=clean_data1_df[_features],            # give clf the input features to visualize how it predicts (all rows in clean_data1_df)\n",
    "    response_method=\"predict\",\n",
    "    alpha=0.4 # use 40% transparency\n",
    ")\n",
    "\n",
    "# this will overlay the input features to show what labels the model will predict\n",
    "# DecisionBoundaryDisplay based on matplotlib, using matplotlib's version of scatter()\n",
    "disp.ax_.scatter(x=clean_data1_df['temperature'], # x-axis for scatter plot\n",
    "                 y=clean_data1_df['pressure'], # y-axis for scatter plot\n",
    "                 c=clean_data1_df['weather_label'], # use target label to colour data points\n",
    "                 edgecolor=\"k\" # use black to show decision boundary\n",
    "                )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab202832",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_wtih_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79302f",
   "metadata": {},
   "source": [
    "## Visualize model performance on test data\n",
    "\n",
    "The model's score on test data was 98.5%.  Let's visualize where the model made its mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d94c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, perform prediction on test set and save prediction to variable `predicted_labels`\n",
    "predicted_labels = clf.predict(X=df_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649fd3a",
   "metadata": {},
   "source": [
    "### Show accuracy of model on test data\n",
    "\n",
    "Create a new dataframe from `df_features_test` to show 'predicted' and 'actual' labels along with a column to show when `predicted!=actual`\n",
    "\n",
    "Call this new dataframe `df_features_test_with_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = df_target_test\n",
    "\n",
    "prediction_df = pd.DataFrame({'predicted': predicted_labels, 'actual': actual_labels})\n",
    "\n",
    "df_features_test_with_predictions = pd.concat([df_features_test, prediction_df], axis=1)\n",
    "\n",
    "df_features_test_with_predictions['difference'] = df_features_test_with_predictions['predicted']!=df_features_test_with_predictions['actual'] # column of boolean\n",
    "df_features_test_with_predictions['difference'] = df_features_test_with_predictions['difference'].astype('int') # cast boolean to integer\n",
    "\n",
    "# show rows where incorrect prediction was made (ie where difference == 1)\n",
    "df_features_test_with_predictions.loc[df_features_test_with_predictions['difference']==1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9952332",
   "metadata": {},
   "source": [
    "### Show where the model made prediction mistakes on the test dataset\n",
    "\n",
    "Yellow dots show where model made incorrect prediction (you have to squint to see the third yellow dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    estimator=clf, \n",
    "    X=df_features_test,  # use features from test dataset\n",
    "    response_method=\"predict\",\n",
    "    alpha=0.4 # use 40% transparency\n",
    ")\n",
    "disp.ax_.scatter(df_features_test_with_predictions['temperature'], df_features_test_with_predictions['pressure'], s=20, c=df_features_test_with_predictions['difference'], edgecolor=\"k\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339df40",
   "metadata": {},
   "source": [
    "# Saving Model for Future Use\n",
    "\n",
    "Save this model for future prediction without having to go through the above training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "model_filename = 'lecture9_logistic_regression_classifier.joblib'\n",
    "dump(clf, model_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a5478",
   "metadata": {},
   "source": [
    "# Loading Existing Model and Running Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97344730",
   "metadata": {},
   "outputs": [],
   "source": [
    " clf = load(model_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4fe70",
   "metadata": {},
   "source": [
    "## Use model to for prediction with new data\n",
    "\n",
    "What happens if we use the model trained on dataset1 with dataset2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_features = ['temperature', 'pressure']\n",
    "_target = 'weather_label'\n",
    "\n",
    "df_features = clean_data2_df[_features]\n",
    "df_target = clean_data2_df[_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86806c6a",
   "metadata": {},
   "source": [
    "### Calculate mean model accuracy on training and test data\n",
    "\n",
    "Why is accuracy so bad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "_features = ['temperature', 'pressure']\n",
    "_target = 'weather_label'\n",
    "\n",
    "print(\"Average model accuracy(new dataset): {0}\".format(clf.score(clean_data2_df[_features], clean_data2_df[_target])))\n",
    "predict_data2 = clf.predict(X=clean_data2_df[_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a106d",
   "metadata": {},
   "source": [
    "### Show what the model is doing\n",
    "\n",
    "When the model is asked to make predictions for new data that is very different from training data, you can see how the model does not generalize well\n",
    "\n",
    "- The left chart shows data that the model was trained on.\n",
    "- The middle chart shows that data points are divided according the decision boundary for Dataset1.  This boundary does not work well with Dataset 2\n",
    "- The right chart shows the actual class labels for Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cef4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "\n",
    "_plot_new_data_df = clean_data2_df[_features].copy()\n",
    "_plot_new_data_df['weather_label'] = predict_data2\n",
    "\n",
    "g1 = sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=clean_data1_df, ax=ax[0])\n",
    "g1.set(title='Dataset 1')\n",
    "g2 = sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=_plot_new_data_df, ax=ax[1])\n",
    "g2.set(title='Prediction on Dataset 2\\nwith model trained on Dataset 1')\n",
    "g3 = sns.scatterplot(x='temperature', y='pressure', hue='weather_label', data=clean_data2_df, ax=ax[2])\n",
    "g3.set(title='Actual class separation for Dataset 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142076a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
